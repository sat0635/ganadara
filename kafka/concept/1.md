<h1>카프카 구조 정리</h1>
<b>Kafka Producer API</b>
<ul>
  <li>Directly producing data
</ul>
<b>Kafka Connect Source API</b>
<ul>
  <li>a bridging between a datastore (we don’t control) and Kafka
</ul>
<b>Kafka Streams API / KSQL</b>
<ul>
  <li>Applications wanting to consume  from Kafka and produce
  <li>If you think you can write your real-time job as SQL-like, use this
</ul>
<b>Kafka Consumer API</b>
<ul>
  <li>Read a stream and perform real-time actions on it
</ul>
<b>Kafka Connect Sink API</b>
<ul>
  <li>Read a stream and store it into a target store
  <li>ex) Kafka to HDFS, Kafka to Msql
</ul>
<h1>카프카 구조에 따른 장단점</h1>
<h3>Kafka Producer API</h3>
<b>Advantages</b>
<ul>
  <li>Extremely simple to use: send data, it’s asynchronous and get a callback
</ul>
<b>Limitations</b>
<ul>
  <li>This will require engineers to write a lot of added logic
</ul>
<h3>Kafka Connect Source API</h3>
<b>Advantages</b>
<ul>
  <li>Producer tasks distribution for parallel processing
  <li>easy mechanism to resume your producer
</ul>
<b>Limitations</b>
<ul>
  <li>If you do not get the chance to find an available source connector for your source code, have to write your own source connector
  <li>Writing your own source connector is actually very good
</ul>
<h3>Kafka Consumer API</h3>
<b>Advantages</b>
<ul>
  <li>Dead-simple, your topics can be consumed in parallel
  <li>Notifications!
</ul>
<b>Limitations</b>
<ul>
  <li>In ETL jobs, Kafka Connect Sinks are better suited as the will avoid you to write some complicated logic against an external data source
</ul>

<h3>Kafka Streams API</h3>
<b>Advantages</b>
<ul>
  <li>completely hides the complexity of maintaining producers and consumers, allowing you to focus on the logic of your stream processors
</ul>
<b>Limitations</b>
<ul>
  <li>you will have to write some code and it could become quite messy and complicated
</ul>
